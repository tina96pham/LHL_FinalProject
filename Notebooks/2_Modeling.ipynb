{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ( AdaBoostClassifier,\n",
    "                                GradientBoostingClassifier,\n",
    "                                BaggingClassifier,\n",
    "                                RandomForestClassifier\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Metric scores\n",
    "from sklearn.metrics import (f1_score,\n",
    "                            accuracy_score,\n",
    "                            recall_score,\n",
    "                            precision_score,\n",
    "                            confusion_matrix,\n",
    "                            roc_auc_score,\n",
    "                            plot_confusion_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "# To impute missing values and handle modeling\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# To be used for tuning the model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# To be used for creating pipelines and personalizing them\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# To supress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "bank_churn= pd.read_csv('/Users/tinapham/Desktop/lighthouse-data-notes/ProJect/LHL_FinalProject/Data/BankChurners.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Dictionary\n",
    "![Alt text](data_dictionary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####                    Drop Irrelavant column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Attrition_Flag            10127 non-null  object \n",
      " 1   Customer_Age              10127 non-null  int64  \n",
      " 2   Gender                    10127 non-null  object \n",
      " 3   Dependent_count           10127 non-null  int64  \n",
      " 4   Education_Level           10127 non-null  object \n",
      " 5   Marital_Status            10127 non-null  object \n",
      " 6   Income_Category           10127 non-null  object \n",
      " 7   Card_Category             10127 non-null  object \n",
      " 8   Months_on_book            10127 non-null  int64  \n",
      " 9   Total_Relationship_Count  10127 non-null  int64  \n",
      " 10  Months_Inactive_12_mon    10127 non-null  int64  \n",
      " 11  Contacts_Count_12_mon     10127 non-null  int64  \n",
      " 12  Credit_Limit              10127 non-null  float64\n",
      " 13  Total_Revolving_Bal       10127 non-null  int64  \n",
      " 14  Avg_Open_To_Buy           10127 non-null  float64\n",
      " 15  Total_Amt_Chng_Q4_Q1      10127 non-null  float64\n",
      " 16  Total_Trans_Amt           10127 non-null  int64  \n",
      " 17  Total_Trans_Ct            10127 non-null  int64  \n",
      " 18  Total_Ct_Chng_Q4_Q1       10127 non-null  float64\n",
      " 19  Avg_Utilization_Ratio     10127 non-null  float64\n",
      "dtypes: float64(5), int64(9), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop ['CLIENTNUM']\n",
    "bank_churn= bank_churn.drop(columns='CLIENTNUM')\n",
    "# Drop the last 2 columns in the DataFrame\n",
    "bank_churn = bank_churn.iloc[:, :-2]\n",
    "# Checking the DataFrame\n",
    "bank_churn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out data categorical data\n",
    "category=bank_churn.select_dtypes(exclude=np.number)\n",
    "# Drop categorical feature\n",
    "numerical= bank_churn.drop(columns=category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unknown data in object datatype but does not contribute to any missing data in numerical data. The unknown category will be kept as is.\n",
    "- Outlier observe from distribution plot in EDA:\n",
    "    - ['Total_Amt_Chng_Q4_Q1']>=2.5\n",
    "    - ['Total_Ct_Chng_Q4_Q1']>=2.7\n",
    "    - ['Total_Trans_Ct']>=135\n",
    "- To be remove in data preprocessing prior to modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data for modeling: 10115\n"
     ]
    }
   ],
   "source": [
    "# Create a model data frame and removing outlier\n",
    "model_df= bank_churn.copy()\n",
    "model_df= model_df[model_df['Total_Amt_Chng_Q4_Q1']<=2.5]\n",
    "model_df= model_df[model_df['Total_Ct_Chng_Q4_Q1']<=2.7]\n",
    "model_df= model_df[model_df['Total_Trans_Ct']<=135]\n",
    "\n",
    "print('Number of data for modeling:',model_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target and encoding y\n",
    "y= model_df['Attrition_Flag'].replace(to_replace={'Attrited Customer': 1, 'Existing Customer': 0})\n",
    "# Drop target variable and with no significant different in EDA\n",
    "drop_column= ['Attrition_Flag','Months_on_book', 'Dependent_count']\n",
    "X = model_df.drop(columns=drop_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dummy variables to categorical data\n",
    "X = pd.get_dummies(\n",
    "    data=X,\n",
    "    columns=[\n",
    "        \"Gender\",\n",
    "        \"Education_Level\",  # has missing values\n",
    "        \"Marital_Status\",  # has missing val\n",
    "        \"Income_Category\",\n",
    "        \"Card_Category\",\n",
    "    ],\n",
    "    drop_first=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data\n",
    "- With imbalance in class from target value, with 16.1% attrited customer, K-fold stratified validiation will be included to consider for class imbalance\n",
    "- Split data into 3 set:\n",
    "    - test set\n",
    "    - train set\n",
    "    - validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "X_training, X_test, y_training, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Split training dataset into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, test_size=0.25, random_state=42, stratify=y_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train Data:\n",
      "0    0.839018\n",
      "1    0.160982\n",
      "Name: Attrition_Flag, dtype: float64\n",
      "========================================\n",
      "\n",
      "Value counts for Validation Data:\n",
      "0    0.839348\n",
      "1    0.160652\n",
      "Name: Attrition_Flag, dtype: float64\n",
      "========================================\n",
      "\n",
      "Value counts for Test Data:\n",
      "0    0.839348\n",
      "1    0.160652\n",
      "Name: Attrition_Flag, dtype: float64\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'Train Data': y_train,\n",
    "    'Validation Data': y_val,\n",
    "    'Test Data': y_test\n",
    "}\n",
    "\n",
    "for dataset_name, data in datasets.items():\n",
    "    value_counts = data.value_counts(normalize=True)\n",
    "    print(f\"Value counts for {dataset_name}:\\n{value_counts}\\n{'='*40}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Data\n",
    "scaler= StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_val= scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>ROC AUC Mean</th>\n",
       "      <th>ROC AUC STD</th>\n",
       "      <th>Accuracy Mean</th>\n",
       "      <th>Accuracy STD</th>\n",
       "      <th>Recall Mean</th>\n",
       "      <th>Recall STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>98.77</td>\n",
       "      <td>0.36</td>\n",
       "      <td>96.29</td>\n",
       "      <td>0.42</td>\n",
       "      <td>82.80</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>98.66</td>\n",
       "      <td>0.37</td>\n",
       "      <td>95.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>76.25</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>90.38</td>\n",
       "      <td>1.84</td>\n",
       "      <td>88.85</td>\n",
       "      <td>1.30</td>\n",
       "      <td>47.70</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>88.63</td>\n",
       "      <td>1.72</td>\n",
       "      <td>93.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>80.96</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes Classifier</td>\n",
       "      <td>87.68</td>\n",
       "      <td>1.56</td>\n",
       "      <td>89.72</td>\n",
       "      <td>1.06</td>\n",
       "      <td>61.41</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>87.56</td>\n",
       "      <td>1.67</td>\n",
       "      <td>88.73</td>\n",
       "      <td>1.37</td>\n",
       "      <td>54.76</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>81.20</td>\n",
       "      <td>2.12</td>\n",
       "      <td>83.90</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Algorithm  ROC AUC Mean  ROC AUC STD  Accuracy Mean  \\\n",
       "6                   XGBoost         98.77         0.36          96.29   \n",
       "5             Random Forest         98.66         0.37          95.21   \n",
       "0       Logistic Regression         90.38         1.84          88.85   \n",
       "4  Decision Tree Classifier         88.63         1.72          93.84   \n",
       "3    Naive Bayes Classifier         87.68         1.56          89.72   \n",
       "2                       KNN         87.56         1.67          88.73   \n",
       "1                       SVM         81.20         2.12          83.90   \n",
       "\n",
       "   Accuracy STD  Recall Mean  Recall STD  \n",
       "6          0.42        82.80        1.35  \n",
       "5          0.62        76.25        4.61  \n",
       "0          1.30        47.70        4.08  \n",
       "4          0.91        80.96        4.55  \n",
       "3          1.06        61.41        2.21  \n",
       "2          1.37        54.76        4.94  \n",
       "1          0.07         0.00        0.00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('Naive Bayes Classifier', GaussianNB()))\n",
    "models.append(('Decision Tree Classifier', DecisionTreeClassifier()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append(('XGBoost', GradientBoostingClassifier()))\n",
    "\n",
    "# Model Evaluation \n",
    "acc_results = []\n",
    "auc_results = []\n",
    "recall_results= []\n",
    "#cross_val_score_train=[]\n",
    "names = []\n",
    "\n",
    "# Dataframe of results\n",
    "col = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', 'Accuracy Mean', 'Accuracy STD', 'Recall Mean', 'Recall STD']\n",
    "model_results = pd.DataFrame(columns=col)\n",
    "i = 0\n",
    "# K-fold validation of model\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10)\n",
    "    # accuracy:\n",
    "    cv_acc_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # recall:\n",
    "    cv_recall_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'recall')\n",
    "    # roc_auc:\n",
    "    cv_auc_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name, round(cv_auc_results.mean()*100, 2), round(cv_auc_results.std()*100, 2),\n",
    "                            round(cv_acc_results.mean()*100, 2), round(cv_acc_results.std()*100, 2),\n",
    "                            round(cv_recall_results.mean()*100, 2),round(cv_recall_results.std()*100, 2) ]\n",
    "    i += 1\n",
    "    \n",
    "model_results.sort_values(by=['ROC AUC Mean'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGboost is the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================================\n",
    "# XGBoost regression: \n",
    "# Parameters: \n",
    "# n_estimators  \"Number of gradient boosted trees. Equivalent to number \n",
    "#                of boosting rounds.\"\n",
    "# learning_rate \"Boosting learning rate (also known as “eta”)\"\n",
    "# max_depth     \"Maximum depth of a tree. Increasing this value will make \n",
    "#                the model more complex and more likely to overfit.\" \n",
    "#=========================================================================\n",
    "classifier=xgb.XGBClassifier(eval_metric='accuracy')\n",
    "\n",
    "#=========================================================================\n",
    "# exhaustively search for the optimal hyperparameters\n",
    "#=========================================================================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# set up our search grid\n",
    "param_grid = {\"max_depth\":    [4, 5],\n",
    "              \"n_estimators\": [500, 600, 700],\n",
    "              \"learning_rate\": [0.01, 0.015]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(classifier, param_grid, cv=5).fit(X_train, y_train)\n",
    "\n",
    "print(\"The best hyperparameters are \",search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHL_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
